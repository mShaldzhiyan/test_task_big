{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from skimage.morphology import convex_hull_image, area_closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  load all images from a directory\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    filenames = []\n",
    "    for filename in tqdm(os.listdir(folder)):\n",
    "        try:\n",
    "            img = Image.open(os.path.join(folder,filename))\n",
    "            if img is not None:\n",
    "                if img.mode != 'RGB':\n",
    "                    img = img.convert('RGB')\n",
    "                images.append(img)\n",
    "                filenames.append(filename)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return images, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all jsons from a directory\n",
    "def load_jsons_from_folder(folder):\n",
    "    jsons = []\n",
    "    filenames = []\n",
    "    for filename in tqdm(os.listdir(folder)):\n",
    "        try:\n",
    "            json = pd.read_json(os.path.join(folder,filename))\n",
    "            if json is not None:\n",
    "                jsons.append(json)\n",
    "                filenames.append(filename)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return jsons, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_parsing = load_images_from_folder('Task/dataset/human_parsing')\n",
    "image = load_images_from_folder('Task/dataset/image')\n",
    "pose_img = load_images_from_folder('Task/dataset/pose_img')\n",
    "pose_json = load_jsons_from_folder('Task/dataset/pose_json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['human_parsing'] = human_parsing[0]\n",
    "df['image'] = image[0]\n",
    "df['pose_img'] = pose_img[0]\n",
    "df['pose_json'] = pose_json[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert all(human_parsing[1] == image[1] == pose_img[1])\n",
    "df_names = pd.DataFrame()\n",
    "df_names['human_parsing'] = human_parsing[1]\n",
    "df_names['image'] = image[1]\n",
    "df_names['pose_img'] = pose_img[1]\n",
    "df_names['pose_json'] = pose_json[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images_df(df, index):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(20, 20))\n",
    "    axs[0].imshow(df['human_parsing'][index])\n",
    "    axs[1].imshow(df['image'][index])\n",
    "    axs[2].imshow(df['pose_img'][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images_df(df, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pose_keypoints'] = df.pose_json.apply(lambda x: x.people[0].get('pose_keypoints_2d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw circles for each dot in poses and add annotation with number of big size\n",
    "def draw_pose(img, poses):\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for i in range(0, len(poses), 3):\n",
    "        draw.ellipse((poses[i]-5, poses[i+1]-5, poses[i]+5, poses[i+1]+5), fill=(255, 0, 0, 255))\n",
    "        draw.text((poses[i], poses[i+1]), str(i//3), fill=(255, 0, 0, 0), font= ImageFont.truetype(\"arial.ttf\", 30))\n",
    "    return img\n",
    "draw_pose(df.image[0], df.pose_keypoints[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_colors = {(64, 0, 128), (192, 0, 0)}\n",
    "legs_colors = {(128,64,0), (0,64,0)}\n",
    "skirt_colors = short_colors.union(legs_colors)\n",
    "skirt_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shirt_colors = {(128,0,128)}\n",
    "hands_colors = {(192,128,128),(64,128,128)}\n",
    "body_colors = shirt_colors.union(hands_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_mask(img, colors):\n",
    "    img = np.array(img)\n",
    "    mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "    for color in colors:\n",
    "        mask += np.all(img == color, axis=-1).astype(np.uint8)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_legs_and_shorts = [get_color_mask(a, skirt_colors) for a in tqdm(human_parsing[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_upper_body = [get_color_mask(a, body_colors) for a in tqdm(human_parsing[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_shirts = [get_color_mask(a, shirt_colors) for a in tqdm(human_parsing[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "mask_shirts_closed = [area_closing(a, 300) for a in tqdm(mask_shirts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convex_shirts = [convex_hull_image(a) for a in tqdm(mask_shirts)]\n",
    "convex_skirts = [convex_hull_image(a) for a in tqdm(mask_legs_and_shorts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names.loc[df_names.image.str.contains('48366')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(convex_shirts[235])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(area_closing(mask_shirts[235], area_threshold=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skirt = convex_skirts[235]\n",
    "shirt = area_closing(mask_shirts[235], 1000)\n",
    "imshow(skirt^skirt*shirt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply skirt mask as gray color\n",
    "def apply_mask(img, mask):\n",
    "    img = np.array(img)\n",
    "    img[mask] = (128, 128, 128)\n",
    "    return Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_images = [apply_mask(a, b) for a, b in tqdm(zip(df.image, convex_skirts))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed_images'] = processed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save processed_images to /preprocessed\n",
    "for i, img in tqdm(enumerate(processed_images)):\n",
    "    img.save('C:/code/python/test_task_big/preprocessed/' + df_names.image[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo:\n",
    "# delete regions of skirt mask that are inside "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skirts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89f085fd51f8d48a6db4ab3f88b5fca8f0c994474eaa3e43a6c160d94f56ce99"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
